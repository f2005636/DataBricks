{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('myproj').getOrCreate()\ndata = spark.read.csv('/FileStore/tables/Bike_Share.csv',inferSchema=True,header=True)\ndata.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- instant: integer (nullable = true)\n-- dteday: timestamp (nullable = true)\n-- season: integer (nullable = true)\n-- yr: integer (nullable = true)\n-- mnth: integer (nullable = true)\n-- hr: integer (nullable = true)\n-- holiday: integer (nullable = true)\n-- weekday: integer (nullable = true)\n-- workingday: integer (nullable = true)\n-- weathersit: integer (nullable = true)\n-- temp: double (nullable = true)\n-- atemp: double (nullable = true)\n-- hum: double (nullable = true)\n-- windspeed: double (nullable = true)\n-- casual: integer (nullable = true)\n-- registered: integer (nullable = true)\n-- cnt: integer (nullable = true)\n\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["data.describe('cnt').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------------------+\nsummary|               cnt|\n+-------+------------------+\n  count|             17379|\n   mean|189.46308763450142|\n stddev| 181.3875990918646|\n    min|                 1|\n    max|               977|\n+-------+------------------+\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["#cnt = casual + registered\n#season and dteday are coverd by yr, mnth, and weekday\n#holiday and weekday are highly correlated with workingday\n#instant is row index column\n#atemp is highly correlated with temp\ndata = data.drop(\"casual\", \"registered\", \"dteday\", \"season\", \"holiday\", \"weekday\", \"instant\", \"atemp\")\ndata.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- yr: integer (nullable = true)\n-- mnth: integer (nullable = true)\n-- hr: integer (nullable = true)\n-- workingday: integer (nullable = true)\n-- weathersit: integer (nullable = true)\n-- temp: double (nullable = true)\n-- hum: double (nullable = true)\n-- windspeed: double (nullable = true)\n-- cnt: integer (nullable = true)\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["from pyspark.mllib.stat import Statistics\nimport pandas as pd\ncol_names = data.columns\nfeatures = data.rdd.map(lambda row: row[0:])\ncorr_mat=Statistics.corr(features, method=\"pearson\")\ncorr_df = pd.DataFrame(corr_mat)\ncorr_df.index, corr_df.columns = col_names, col_names\nprint(corr_df.to_string())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">                  yr      mnth        hr  workingday  weathersit      temp       hum  windspeed       cnt\nyr          1.000000 -0.010473 -0.003867   -0.002196   -0.019157  0.040913 -0.083546  -0.008740  0.250495\nmnth       -0.010473  1.000000 -0.005772   -0.003477    0.005400  0.201691  0.164411  -0.135386  0.120638\nhr         -0.003867 -0.005772  1.000000    0.002285   -0.020203  0.137603 -0.276498   0.137252  0.394071\nworkingday -0.002196 -0.003477  0.002285    1.000000    0.044672  0.055390  0.015688  -0.011830  0.030284\nweathersit -0.019157  0.005400 -0.020203    0.044672    1.000000 -0.102640  0.418130   0.026226 -0.142426\ntemp        0.040913  0.201691  0.137603    0.055390   -0.102640  1.000000 -0.069881  -0.023125  0.404772\nhum        -0.083546  0.164411 -0.276498    0.015688    0.418130 -0.069881  1.000000  -0.290105 -0.322911\nwindspeed  -0.008740 -0.135386  0.137252   -0.011830    0.026226 -0.023125 -0.290105   1.000000  0.093234\ncnt         0.250495  0.120638  0.394071    0.030284   -0.142426  0.404772 -0.322911   0.093234  1.000000\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(inputCols=['yr','mnth','hr','workingday','weathersit','temp','hum','windspeed'],outputCol='features')\noutput = assembler.transform(data)\nfinal_data = output.select('features','cnt')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.ml.regression import GeneralizedLinearRegression\nglr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.0, labelCol='cnt')\nmodel = glr.fit(final_data)\nsummary = model.summary\nprint(\"Coefficients: \" + str(model.coefficients))\nprint(\"Intercept: \" + str(model.intercept))\nprint(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\nprint(\"T Values: \" + str(summary.tValues))\nprint(\"P Values: \" + str(summary.pValues))\nprint(\"AIC: \" + str(summary.aic))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Coefficients: [80.6070235728,5.08988834706,7.65591400666,6.5609103192,-4.20164789921,301.015773794,-194.191083747,24.0796769961]\nIntercept: -3.591256782869093\nCoefficient Standard Errors: [2.175166632995379, 0.3282379138190242, 0.16557195957694057, 2.3308634070201713, 1.9114877733884503, 5.844330571793608, 6.901165784363383, 9.425643371396651, 6.5196975954424286]\nT Values: [37.057861384062, 15.506704535863488, 46.23919428276566, 2.814798284376211, -2.198103465637391, 51.50560360947058, -28.13888114200394, 2.5546985014452677, -0.5508318032081041]\nP Values: [0.0, 0.0, 0.0, 0.004886277319453569, 0.027954878766552227, 0.0, 0.0, 0.010636431434967397, 0.5817560647532338]\nAIC: 221724.7008802438\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml.regression import GeneralizedLinearRegression\nglr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.0, labelCol='cnt', fitIntercept=False)\nmodel = glr.fit(final_data)\nsummary = model.summary\nprint(\"Coefficients: \" + str(model.coefficients))\nprint(\"Intercept: \" + str(model.intercept))\nprint(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\nprint(\"T Values: \" + str(summary.tValues))\nprint(\"P Values: \" + str(summary.pValues))\nprint(\"AIC: \" + str(summary.aic))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Coefficients: [80.3412224847,5.0587763955,7.62392125749,6.28986934261,-4.28002531174,299.803176474,-196.518508615,21.8344372674]\nIntercept: 0.0\nCoefficient Standard Errors: [2.1209243009248273, 0.323335346012136, 0.15504751201328415, 2.27828781860648, 1.906146265912169, 5.4137688346198125, 5.456354832851995, 8.498549933935461]\nT Values: [37.88028759424551, 15.64560280184728, 49.17151625647387, 2.7607878562307886, -2.2453813688257, 55.377905047704665, -36.016445893866255, 2.5691956200909556]\nP Values: [0.0, 0.0, 0.0, 0.005772261265023726, 0.0247561843021602, 0.0, 0.0, 0.010201758509832404]\nAIC: 221723.004450478\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\nmy_eval = RegressionEvaluator().setLabelCol(\"cnt\")\nresults = model.transform(final_data)\nresults.describe('prediction').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-------------------+\nsummary|         prediction|\n+-------+-------------------+\n  count|              17379|\n   mean| 189.56190471767115|\n stddev| 112.01063820342674|\n    min|-120.76132152786755|\n    max| 499.50524649746524|\n+-------+-------------------+\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["RMSE = my_eval.evaluate(results)\nRMSE"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>142.53579425441478\n</div>"]}}],"execution_count":9}],"metadata":{"name":"Bike_Share","notebookId":2568235444311122},"nbformat":4,"nbformat_minor":0}
